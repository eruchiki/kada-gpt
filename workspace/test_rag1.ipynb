{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f2b288-0d65-43db-a738-3a86c9ba3504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import download_loader\n",
    "\n",
    "CJKPDFReader = download_loader(\"CJKPDFReader\")\n",
    "loader = CJKPDFReader()\n",
    "documents = loader.load_data(file=\"pdf_data/data_1.pdf\")\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3785d223-28f6-42a3-966a-910e5c1d8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./pdf_to_text/pdf_to_text_1.txt\",encoding=\"utf-8\",mode=\"w\") as f:\n",
    "    f.write(documents[0].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784961eb-166f-44d6-8a99-3d7514499e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful: <qdrant_client.qdrant_client.QdrantClient object at 0x7f77c0cad590>\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient,models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "connection = QdrantClient(host='qdrant', port=6333)\n",
    "print(\"Connection successful:\", connection)\n",
    "\n",
    "connection.create_collection(\n",
    "    collection_name=\"test_rag1\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
    ")\n",
    "info = connection.get_collection(collection_name=\"test_rag1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2bf6c77-9281-4f50-8673-e8562b38993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import uuid\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",chunk_size=1000,chunk_overlap=200,length_function=len)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def get_embedding(text_chunks, model_id=\"text-embedding-ada-002\"):\n",
    "    points = []\n",
    "    for idx, chunk in enumerate(text_chunks):\n",
    "        response = openai.Embedding.create(\n",
    "            input=chunk,\n",
    "            model=model_id\n",
    "        )\n",
    "        embeddings = response['data'][0]['embedding']\n",
    "        point_id = str(uuid.uuid4())  # Generate a unique ID for the point\n",
    "        points.append(PointStruct(id=point_id, vector=embeddings, payload={\"text\": chunk}))\n",
    "\n",
    "    return points\n",
    "\n",
    "def insert_data(get_points):\n",
    "    operation_info = connection.upsert(\n",
    "        collection_name=\"test_rag1\",\n",
    "        wait=True,\n",
    "        points=get_points\n",
    "    )\n",
    "\n",
    "def create_answer_with_context(query):\n",
    "    response = openai.Embedding.create(\n",
    "        input=query,\n",
    "\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    search_result = connection.search(\n",
    "        collection_name=\"test_rag1\",\n",
    "        query_vector=embeddings,\n",
    "        limit=3\n",
    "    )\n",
    "    print(\"Question: \" ,query,'\\n')\n",
    "    print(\"Searching.......\\n\")\n",
    "    prompt=\"\"\n",
    "    for result in search_result:\n",
    "        prompt += result.payload['text']\n",
    "    concatenated_string = \" \".join([prompt,query])\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": concatenated_string}\n",
    "        ]\n",
    "        )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    get_raw_text=documents[0].text\n",
    "    chunks=get_text_chunks(get_raw_text)\n",
    "    vectors=get_embedding(chunks)\n",
    "    \n",
    "    insert_data(vectors)\n",
    "    question=\"提案手法の概要を説明してください\"\n",
    "    answer=create_answer_with_context(question)\n",
    "    print(\"Answer : \",answer,\"\\n\")\n",
    "    print(\"searching completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91605586-7063-4047-8424-61fb0b1f6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  提案手法の概要を説明してください \n",
      "\n",
      "Searching.......\n",
      "\n",
      "Answer :  本研究では、機械学習における異常検知モデルの学習データセットを圧縮するための手法を提案しています。提案手法の概要は以下の通りです。\n",
      "\n",
      "1. 位置合わせ: データセット内の各画像のオブジェクトの位置を合わせるために、マスク画像を使用します。これにより、オブジェクトが干渉しない範囲の背景を削除することができます。\n",
      "\n",
      "2. 背景削除: マスク画像を使用して、オブジェクト以外の背景を削除します。この処理により、データ間の類似性を高めることができます。\n",
      "\n",
      "3. 動画ファイルへの変換: 加工された画像データセットをHEVCを使用して動画ファイルに変換します。HEVCによる変換は、画像データセットのサイズを大幅に縮小することができます。\n",
      "\n",
      "4. 学習とテストに向けた前処理: 学習時には動画ファイルを画像ファイルに復元し、従来の方法で学習を行います。テスト用データも同様に加工して精度の維持を図ります。\n",
      "\n",
      "提案手法の評価では、異常検知モデルの精度を確認し、データサイズの縮小効果や位置合わせ・背景削除の効果を評価します。比較手法として従来の手法やHEVCの圧縮パラメータを変更した手法などを用いて評価を行います。評価結果から、提案手法がモデルの精度を落とさずにデータサイズを縮小できることを確認することが目的です。 \n",
      "\n",
      "searching completed\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ec7af-48c9-456f-b226-654e1e683eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
