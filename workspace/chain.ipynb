{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67019a11-b40a-486c-9046-adb2b547fae3",
   "metadata": {},
   "source": [
    "# LangChainを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80eced48-a494-44cd-b9c7-e6df6d9ed3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.278'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8293113-4ce5-4b32-86d5-e3d41e423e36",
   "metadata": {},
   "source": [
    "## 基本的な生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9dc8e56-a1be-42cf-b437-08ff3a7dc2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.7, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', tiktoken_model_name=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.7)　# temperature(1.0~0.0)が高いとランダム性が高まる\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6fc7fa-3422-497c-b426-714c62751414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「かがわうどん」が香川県で一番おいしいと評判のうどん屋です。\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM ラッパーを初期化\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "# LLM に渡す入力テキスト\n",
    "text = \"香川県で一番おいしいうどん屋は？\"\n",
    "\n",
    "# LLM から予測を受け取って表示\n",
    "prediction = llm(text)\n",
    "print(prediction.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e590a-08b6-460c-a034-5fce82b61b6c",
   "metadata": {},
   "source": [
    "## プロンプトテンプレート作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67aed992-1b01-4378-883e-8f7dd5683037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "旅行の情報を共有するためのSNSアプリに名前を付けたいのですがどのような名前がいいですか？\n",
      "・Traveller's Note\n",
      "・TripShare\n",
      "・JourneyLink\n",
      "・TripFolio\n",
      "・Travelingogue\n",
      "・VoyageFlux\n",
      "・RoamingSphere\n",
      "・MyTripLog\n",
      "・VoyageVibe\n",
      "・TripTrack\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# プロンプトテンプレートの作成\n",
    "llm = OpenAI(temperature=0.7)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"app_content\"],\n",
    "    template=\"{app_content}に名前を付けたいのですがどのような名前がいいですか？\",\n",
    ")\n",
    "\n",
    "# テンプレートからプロンプトを作成\n",
    "app_content = \"旅行の情報を共有するためのSNSアプリ\"\n",
    "mid_prompt = prompt.format(app_content=app_content)\n",
    "print(mid_prompt)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "prediction = chain.run(app_content=app_content)\n",
    "print(prediction.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f27986b-18de-4968-b7bc-ad43036056ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "。\n",
      "\n",
      "・トラベルコネクト\n",
      "・旅のつながり\n",
      "・旅のシェアー\n",
      "・旅のパートナー\n",
      "・旅のハブ\n",
      "・旅のネットワーク\n",
      "・旅のリンク\n",
      "・旅のブリッジ\n",
      "・旅のコネクション\n",
      "・旅のサークル\n",
      "・旅のサイクル\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 複数変数埋め込みも可\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"app_content\",\"request\"],\n",
    "    template=\"{app_content}に名前を付けたいのですがどのような名前がいいですか？{request}\",\n",
    ")\n",
    "\n",
    "# テンプレートからプロンプトを作成\n",
    "app_content = \"旅行の情報を共有するためのSNSアプリ\"\n",
    "request = \"日本語でお願いします\"\n",
    "mid_prompt = prompt.format(app_content=app_content,request=request)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "prediction = chain.run(app_content=app_content,request=request)\n",
    "print(prediction.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340bf373-d9d8-4bc5-8171-a188631e918f",
   "metadata": {},
   "source": [
    "## エージェントを用いる\n",
    "ツール一覧\n",
    "- Serpapi…SerpAPIを使用した検索エンジン\n",
    "- Request(API連携)…特定のサイトからコンテンツを取得するツール\n",
    "- Terminal…コマンド実行\n",
    "- Google Serper…検索エンジンがGoogle\n",
    "- Wikipedia…Wikipedia検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8f932-c045-4c6e-91ed-f3f478d53de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# ツールを指定\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "#エージェントにタスクを実行してもらいます\n",
    "agent.run(\"昨日の東京の最高気温は何度でしたか？摂氏温度でお答え下さい。また、その数値を x としたとき、x^0.23 は何ですか？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167c148-2d59-428c-99d1-bf42ac35dcc9",
   "metadata": {},
   "source": [
    "## 以前の入出力を記憶させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456252f2-b19b-499d-ad5d-b8b86684c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  こんにちは。最近オランダに行きました\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 。\n",
      "\n",
      "おお、おめでとうございます！オランダはどんなところでしたか？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  きれいな町でした\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: It was a beautiful town.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  僕が最近どこに行ったか覚えていますか？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: はい、覚えています。最近、私は東京都内のいくつかの場所に行きました。その中で、最も有名なのは、東京タワーと東京スカイツリーです。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "while True: \n",
    "    command = input(\"You: \")\n",
    "    if command == \"exit\":\n",
    "        break\n",
    "    response = llm(command)\n",
    "    print(f\"AI: {response.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ca3977-088b-43aa-a9db-25581c506890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  こんにちは。最近オランダに行きました\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  こんにちは！オランダに行ったんですね！どんなところですか？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  きれいな町でしたよ。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  そうなんですか！オランダは有名なチェスセンターでもあるんですね。どんなチェスセンターを見ましたか？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  チェスセンターにはいってません。そういえばオランダの首都は知ってますか？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  はい、オランダの首都はアムステルダムです。アムステルダムは、歴史的な建物や文化的な場所がたくさんあるとても美しい町です。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "# 前回のやり取りを記憶する\n",
    "conversation = ConversationChain(llm=llm)\n",
    "while True: \n",
    "    command = input(\"You: \")\n",
    "    if command == \"exit\":\n",
    "        break\n",
    "    response = conversation.predict(input=command)\n",
    "    print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ee93e-59a2-404c-b436-60e89b4e6e00",
   "metadata": {},
   "source": [
    "## 対話に設定入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6d4ad-4e66-456a-9c03-fd2676bfdb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "# チャットモデルで利用可能なメッセージの型をインポート\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "# チャットモデルのラッパーを初期化\n",
    "chat = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# チャットモデルに渡すメッセージを作成する\n",
    "messages = [\n",
    "    SystemMessage(content=\"あなたは親切なアシスタントです。\"),\n",
    "    HumanMessage(content=\"春の季語を絡めた冗談を教えてください。\"),\n",
    "    AIMessage(content=\"「春眠（しゅんみん）暁（ぎょう）を覚（さ）えず」という言葉がありますが、「春は眠くても、アシスタントは覚えてるよ！」と言って、ツッコミを入れるのはいかがでしょうか？笑\"),\n",
    "    HumanMessage(content=\"面白くない。もう一度。\"),\n",
    "]\n",
    "\n",
    "# チャットモデルにメッセージを渡して、予測を受け取る\n",
    "result = chat(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90065d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 8, 20, 21]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(  \n",
    "    separators = \"\\n\", # セパレータ\n",
    "    chunk_size=14,  # チャンクのトークン数\n",
    "    chunk_overlap=0,\n",
    "    length_function = len,  # チャンクオーバーラップのトークン数\n",
    ")\n",
    "text = \"あ\\nあああああ\\nああ\\nあああああ\\nああ\\nあああああああああああああああああああ\\nああああああああああああああああああああ\"\n",
    "result = text_splitter.split_text(text)\n",
    "[len(enc.encode(r)) for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8cec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
