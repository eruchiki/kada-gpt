⼤規模⾔語モデルを⽤いた対話システム
2023.07.21 情報処理学会連続セミナー2023
対話AI最前線︓ChatGPTとその先にある可能性
2023 第三回 情報処理学会連続セミナー © 光⽥航
0
光⽥航（rinna株式会社）

光⽥ 航
r i n n a 株 式 会 社
[経歴]
• 2015年
東京⼯業⼤学⼤学院情報理⼯学研究科 修⼠課程修了
• 2015年〜2023年
⽇本電信電話株式会社 研究員
• 2021年
筑波⼤学⼤学院システム情報⼯学研究群 博⼠（⼯学）
• 2023年
rinna株式会社 Applied Scientist
[専⾨]
• ⾃然⾔語処理
• 対話システム（チャットボット）
Koh  M i t s u da
1
2023 第三回 情報処理学会連続セミナー © 光⽥航

⼤規模⾔語モデルの基礎
2023 第三回 情報処理学会連続セミナー © 光⽥航
2

⼤規模⾔語モデル
2023 第三回 情報処理学会連続セミナー © 光⽥航
3
•
多量のテキストデータを⽤いて学習された，多数のパラメタを持つモデル
– 例. GPT-3: 500 billionトークン（5000億単語）で学習（参考: Wikipediaの⽇本語記事は全部で約20億単語），
パラメタ数は1750億個
•
⼊⼒テキストの続きの予測（次単語予測）に基づき多様なタスクを実施可能
– パラメタ数のグラフはGPT-4のCode Interpreterを⽤いて作成（プログラム⽣成）
GPT-3の学習データ（https://arxiv.org/abs/2005.14165）
https://chat.openai.com

次単語予測
2023 第三回 情報処理学会連続セミナー © 光⽥航
4
⼤規模⾔語モデル（Transformer）
名前
は
LLM
です
</s>
トークン
⽣成確率
LLM
⼈間
ベクトル
何
トークン-ベクトル変換DB
名前は何
⼊⼒テキスト
トークン
対話システム
トークナイズ
出⼒テキスト
モジュールの1つ
https://www.flaticon.com/free-icon/bot_1782391
https://www.flaticon.com/free-icon/languages_3898840

Transformer
2023 第三回 情報処理学会連続セミナー © 光⽥航
5
• Transformer-encoderとTransformer-
decoderからなる深層学習モデル
• 機械翻訳の研究で提案され，⾃然⾔語
処理を中⼼に多様なタスクに適⽤
– 翻訳: フランス語テキスト → 英語テキスト
– 対話: 過去⽂脈 → システムの応答
• encoderやdecoderを多層に積み重ねる
ことでモデルのスケールが可能になり，
性能が⼤きく向上
– BERT: encoderを多層に積んだもの
– GPT-3: decoderを多層に積んだもの
– 近年の対話が可能な⼤規模⾔語モデルは
基本的にdecoder-onlyのモデル
• 各encoderやdecoderの中でセルフアテ
ンションという計算を実施
http://jalammar.github.io/illustrated-transformer/

セルフアテンション
2023 第三回 情報処理学会連続セミナー © 光⽥航
6
•
⼊⼒や出⼒に含まれる全てのトークン間の関係を考慮するための機構
•
各トークン間の類似度計算をベクトルで表現したQueryとKey（辞書引き）で実現
https://towardsdatascience.com/illustr
ated-self-attention-2d627e33b20a 
トークン1（名前）
query1
トークン2（は）
トークン3（何）
全て⾜し合わせ
Self-Attention(トークン1)
key1
value1
key2
value2
key3
value3
和を1に
正規化
weighted
value1
weighted
value3
weighted
value2
類似度計算
score1
score2
score3
トークン2，3（は，何）との関係を考慮したベクトル

⼤規模⾔語モデルの技術的なポイント
2023 第三回 情報処理学会連続セミナー © 光⽥航
7

⼤規模⾔語モデルを⽤いた対話システムの実現
2023 第三回 情報処理学会連続セミナー © 光⽥航
8
• 多量のテキストデータで学習（プレトレーニング）された⼤規模⾔語モデルは，
そのままでは対話システムとしては使うことは難しい
– ⼊⼒されたテキストの続きを出⼒するのみ
• 対話システムを実現させるために，対話できるようにしたり，
個性を持たせたり，知識を⼊れ込んだりしたい
• 機械学習や⾃然⾔語処理の技術を適⽤することで実現可能
– ファインチューニング
– プロンプト（コンテキスト内学習）
– Reinforcement Learning from Human Feedback（RLHF）
– 外部知識（組織内の⽂書や個性等の設定）の参照
https://www.flaticon.com/free-icon/bot_1782391
https://www.flaticon.com/free-icon/languages_3898840
対話システム
⼤規模⾔語モデル

ファインチューニング
2023 第三回 情報処理学会連続セミナー © 光⽥航
9
• 解きたいタスクに合わせて学習データを⽤意し，学習データ中のサンプルを
使ってプレトレーニングしたモデルのパラメタを更新（微調整）する⼿法
– 英仏翻訳のペアと同様に，「⽂脈 => システムの応答」のペアを⽤意すれば対話が可能に
パラメタ更新
パラメタ更新
パラメタ更新
⼊⼒テキスト
右図はhtps://arxiv.org/abs/2005.14165の図の翻訳
学習データ（例. 英仏翻訳）:
⼊⼒テキスト => 正解出⼒テキスト
plush giraffe
…
パラメタ
loutre de mer
⼊⼒テキスト
正解出⼒テキスト
出⼒テキスト
⼤規模⾔語モデル
…
giraffe peluche
正解と出⼒の差分でパラメタを更新

プロンプト（コンテキスト内学習）
2023 第三回 情報処理学会連続セミナー © 光⽥航
10
•
プロンプト: 「⼤規模⾔語モデルに与える⼊⼒テキスト」
– 例. “次の英語をフランス語に翻訳して:
cheese =>”
•
GPT-3にて，ファインチューニング（モデルのパラメタ
更新）を⾏わず，プロンプトのみで多様な⾔語処理タス
クが⾼精度に解けることが発⾒
•
ファインチューニング⽤のデータを⽤意せずとも，プロ
ンプトを⼯夫するのみでも良い出⼒が得られるため注⽬
– ⼊出⼒サンプルの指定: Zero-shot/One-shot/Few-shot
– 思考仮定の出⼒: ”Letʼs think step by step”
•
柔軟に出⼒を制御可能
– 対話の⽅向性を指定: 「有⽤な応答を返して」「共感して」
– 個性を指定: 「ポジティブに」「〇〇のキャラ⾵に」
– 外部知識の参照: 組織内の⽂書やキャラクタの設定等
htps://arxiv.org/abs/2005.14165
https://arxiv.org/abs/2205.11916

Reinforcement Learning from Human Feedback（RLHF）
11
•
ユーザにとって好ましい応答を返すよう，⼈⼿評価のデータを⽤いてモデルを調整
•
例. 情報検索を⾏いつつ対話を⾏うSparrow（Google DeepMind）におけるRLHF
https://storage.googleapis.com/deepmind-media/DeepMind.com/Authors-Notes/sparrow/sparrow-final.pdf
1. 対話向けにファイン
チューニング済みの⼤規
模⾔語モデルを⽤意
2a. ユーザがモデルと実際に対話を
⾏い，各応答の善し悪しを評価
2b.ユーザがモデルがあらかじ
め決められたルール（例: ユー
ザの情報の決め付けはNG）を
逸脱するような対話を試み，
ルールを守れたか評価
3. 集めた評価データを⽤いて，応答を⾃動
的に評価するモデル（1.とは別の⼤規模⾔語
モデル）を学習（ファインチューニング）
4. 1.のモデルが⼀
⼈⼆役となって対話
を⽣成し，3.のモデ
ルで⾃動評価
⾃動評価の結果が⾼
くなるよう，モデル
を更新（強化学習，
Reinforcement 
Learning）
2a.と2b.に戻る
（以降繰り返し）

2023 第三回 情報処理学会連続セミナー © 光⽥航
12
•
⼊⼒に関連の深いテキストを外部知識から検索し，プロンプトに挿⼊して⽣成（Retrieval Augmented 
Generation）
•
外部知識（例: Wikipediaの新しい記事，組織内の⽂書，キャラクタ設定）を考慮した⽣成が可能に
https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-
intelligent-natural-language-processing-models/
ベクトルを⽤いた外部知識の検索
⼤規模⾔語モデル
“Hemingwayの質問の
内容に関連する⽂書
“Hemingway”に
ついての質問
“Hemingway”の質問に
関連する⽂書を
踏まえた応答
プロンプト
挿⼊
外部知識（組織内の⽂書や個性等の設定）の参照
挿⼊

⼤規模⾔語モデルの技術的なポイントのまとめ
2023 第三回 情報処理学会連続セミナー © 光⽥航
13
技術的なポイント
必要なリソース
調整の難易度
試す順番
ファインチューニング
•
モデルのパラメタデータ
•
ファインチューニング⽤
データ
•
ファインチューニング⽤
プログラム
•
GPU
NORMAL K
3番
プロンプト
（コンテキスト内学習）
なし
VERY EASY J
1番
RLHF
•
モデルのパラメタデータ
•
RLHF⽤データ
•
RLHF⽤プログラム
•
GPU
VERY HARD L
4番
外部知識の参照
•
外部知識のテキストデータ
•
知識検索プログラム
EASY J
2番
• 必要なリソースや難易度が異なるため，1番から順に試していくことをおすすめ

⼤規模⾔語モデルに関するツール
2023 第三回 情報処理学会連続セミナー © 光⽥航
14

⼤規模⾔語モデルを⽤いた対話システム開発の流れ
2023 第三回 情報処理学会連続セミナー © 光⽥航
15
4. 対話システム化
3. ⼤規模⾔語モデルの調整
2. ベースとする⼤規模⾔語モデルの選定
1. 実現したい対話内容の決定

ツール: ⼤規模⾔語モデルの選定
2023 第三回 情報処理学会連続セミナー © 光⽥航
16
• ⽇本語を対象とした対話を⾏う場合，⽇本語が得意な⼤規模⾔語モデルの利⽤
を推奨
– 英語を対象にしたモデルでは⽇本語の学習データ量が少なく，⼗分な性能が出づらい
• ⽇本語が得意な⼤規模⾔語モデル
ライセンス
モデルの例（⽣成型）
特徴 J / L
⾮オープンソース
•
OpenAIのChatGPT，
GPT-4
•
GoogleのBard 等
•
利⽤ハードル低↓
（チャット画⾯やAPIを
利⽤）
•
カスタマイズ性低↓
（API経由のみ）
•
コスト⾼↑
（API呼び出し数で課⾦）
オープンソース
•
rinnaのjapanese-
gpt-neox-3.6b
•
CyberAgentの
OpenCALM-7B 等
•
カスタマイズ性⾼↑
（柔軟なモデル改善）
•
コスト低↓
（GPU利⽤コストのみ）
•
利⽤ハードル⾼↑
（⾃然⾔語処理や機械
学習等の知識が必要）

ツール: ⼤規模⾔語モデルの調整と対話システム化
2023 第三回 情報処理学会連続セミナー © 光⽥航
17
•
学習データ，外部知識
– ウィキペディア
• https://www.tensorflow.org/datasets/catalog/wiki40b
• 前処理済みのものがおすすめ
– ⽇本語対話コーパスのまとめ
• https://individuality.jp/dialogue_corpus.html
– オープンソースの⽇本語LLMまとめ
• https://github.com/llm-jp/awesome-japanese-llm
• 学習に利⽤されているデータを参照
– クリーニング⽅法
• https://arxiv.org/abs/2302.13971
•
学習や推論のフレームワーク
– Hugging Face
• https://huggingface.co
• ⼤規模⾔語モデル，データセット，学習や推論を⾏うためのプログラムがまとまったもの
– ⼤規模⾔語モデルを各種ツールと組み合わせるための選択肢
• LangChain: https://langchain.com
• LlamaIndex: https://www.llamaindex.ai
• （Python等で⾃分で実装）

ツール: ⼤規模⾔語モデルの調整と対話システム化（つづき）
2023 第三回 情報処理学会連続セミナー © 光⽥航
18
• 学習や推論を効率化／⾼速化するライブラリ
– ファインチューニング
• Parameter-Efficient Fine-Tuning（PEFT）: https://github.com/huggingface/peft
– 推論
• CPU（⾮GPU）推論: https://github.com/ggerganov/llama.cpp
• 効率化⼿法の⼀覧・⽐較の記事: https://zenn.dev/rinna/articles/5fd4f3cc12f7c5
– モデルの軽量化
• 量⼦化: https://huggingface.co/blog/4bit-transformers-bitsandbytes
• テキストからベクトルを作成するためのAPIやモデル
– ベクトル化
• OpenAI API（Embeddings）: https://platform.openai.com/docs/guides/embeddings
• Sentence-Transformers: https://www.sbert.net
– ⾼速ベクトル検索
• FAISS: https://github.com/facebookresearch/faiss

実装デモ
2023 第三回 情報処理学会連続セミナー © 光⽥航
19

デモ: ⼤規模⾔語モデルを⽤いた対話システム
2023 第三回 情報処理学会連続セミナー © 光⽥航
20
https://colab.research.google.com/drive/1WKAFaeXPSDOJ6ujwOwj55QQnUr2YsNFU?usp=sharing
Google Collaboratoryという，ブラウザ上でPythonを実⾏可能な環境を利⽤
（環境設定が不要で，料⾦なしでGPUアクセスも可能）

まとめ
2023 第三回 情報処理学会連続セミナー © 光⽥航
21
⼤規模⾔語モデルの技術や，⼤規模⾔語モデルを⽤いて対話システムを実現する
⽅法について解説
• ⼤規模⾔語モデルの基礎
– 次単語予測に基づいて多様なタスクを実施
– Transformer，セルフアテンション
• ⼤規模⾔語モデルの技術的なポイント
– ファインチューニング，プロンプト，RLHF，
外部知識の参照
• ⼤規模⾔語モデルに関するツール
– ⼤規模⾔語モデルの選択肢
– ⼤規模⾔語モデルを調整する⼿段
– 対話システムとして実装する⼿段
• 実装デモ
– 対話向けのファインチューニング
Limitations
•
⼀⾒妥当だが誤ったことや⾮常識な応答を
出⼒
•
⼊⼒の表現に敏感
•
応答が冗⻑であったり，特定のフレーズを
多⽤したり
•
ユーザからの曖昧な⼊⼒に対して明確化せず
応答
•
有害な⼊⼒への反応や偏⾒を含む応答
今後の課題: ChatGPTのリリース記事より
https://openai.com/blog/chatgpt/
⼤規模⾔語モデルを⽤いた対話システムの性能はまだ100
点満点とは⾔えないかもしれないが，技術発達の速度は⾮
常に早く，今後課題の解決とともに，より多様な分野へと
応⽤されていくことが期待

