{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b98868-90a3-41fd-b545-66da34568d01",
   "metadata": {},
   "source": [
    "# Llama_Indexを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29365fa-f644-4b99-860a-40fce2cd853b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.24.post1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llama_index\n",
    "llama_index.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af1965-158b-4374-8723-0845674311a0",
   "metadata": {},
   "source": [
    "## PDFを読み込む\n",
    "- 読み込み可能なアプリケーション\n",
    "  - dvipdfmx\n",
    "  - word\n",
    "- 読み込みがうまくかないアプリケーション\n",
    "  - Adobe\n",
    "  - iText\n",
    "\n",
    "- 使用データ\n",
    "  - [STクラウドサーバーサービス契約約款](https://www.stnet.co.jp/cmmn/data/stcloud.pdf)\n",
    "  - [インターネットセキュリティサービス契約約款\n",
    "(https://www.stnet.co.jp/cmmn/data/inet.pdf)\n",
    "  - [ビジネス光ネットサービス契約約款](https://www.stnet.co.jp/cmmn/data/oshigotonet.pdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b79959-f00a-4899-9289-cd58b208fe15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import download_loader\n",
    "\n",
    "CJKPDFReader = download_loader(\"CJKPDFReader\")\n",
    "loader = CJKPDFReader()\n",
    "documents = loader.load_data(file=\"pdf_data/data_0.pdf\")\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e4576d-4347-4902-a136-4a80ff1b9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./pdf_to_text/pdf_to_text_0.txt\",encoding=\"utf-8\",mode=\"w\") as f:\n",
    "    f.write(documents[0].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b47a701-8b03-47b0-b07a-49052b351b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'hash', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator', 'class_name'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].to_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "007a04a7-e9eb-4efc-9371-9fc151c290c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = documents[0].text.split(\"\\n\\n\")\n",
    "text_data = [text.replace(\"\\n\",\"\") for text in text_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c8218e2-f69a-4a88-873e-7da9550a1ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc89343c-9001-4650-8e73-294fbff0d8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IA0248_02tanaka (2021-03-05 15:41)\\n\\n一般論文\\n\\n雑談対話応答における連続する事態の一貫性と対話継続性の関係\\n\\n田中\\u3000翔平 †・吉野幸一郎 †,††・須藤\\u3000克仁 †・中村\\u3000\\u3000哲 †\\n\\n雑談対話システムの評価指標として，ユーザとの対話を継続させる働きを表す，対話\\n継続性が挙げられる．対話モデルの先行研究において，対話継続性の向上には，シ\\nステム発話の一貫性が重要であ'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfae875-3469-446d-afb9-1c5693c503e5",
   "metadata": {},
   "source": [
    "## Qdrantの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cfd49b-32d1-4d5a-9dd2-8d8ccab10e8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QdrantVectorStore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(stream\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout, level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[1;32m      8\u001b[0m logging\u001b[38;5;241m.\u001b[39mgetLogger()\u001b[38;5;241m.\u001b[39maddHandler(logging\u001b[38;5;241m.\u001b[39mStreamHandler(stream\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout))\n\u001b[0;32m---> 10\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mQdrantVectorStore\u001b[49m(client\u001b[38;5;241m=\u001b[39mclient, collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults(vector_store\u001b[38;5;241m=\u001b[39mvector_store)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'QdrantVectorStore' is not defined"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "import logging\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import sys\n",
    "\n",
    "client = qdrant_client.QdrantClient(host='qdrant', port=6333)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eead1-642c-4ac9-ac99-c227128dbb50",
   "metadata": {},
   "source": [
    "## ベクトル化\n",
    "### note\n",
    "- 文分割は読点等のsplit程度\n",
    "- データごとに処理が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b8810ad-8513-44b7-9b96-db07ba4ccbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_separator = \"\\n\\n\" # 段落分割\n",
    "chunk_size = 1024 #チャンク（トークン）数\n",
    "chunk_overlap = 20 # 前のチャンクをどのくらい含めるか\n",
    "secondary_chunking_regex = '[^,.．;。]+[,.．;。]?'# 文分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c1a3193-13c0-4590-a823-89ef7a987523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNodeParser(text_splitter=SentenceSplitter(chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n', secondary_chunking_regex='[^,.．;。]+[,.．;。]?', chunking_tokenizer_fn=<function sent_tokenize at 0x7f4b8e8ef6a0>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7f4bcf9d0d50>, tokenizer=functools.partial(<bound method Encoding.encode of <Encoding 'gpt2'>>, allowed_special='all')), include_metadata=True, include_prev_next_rel=True, metadata_extractor=None, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7f4bcfb6ab90>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.text_splitter import SentenceSplitter\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import VectorStoreIndex,ServiceContext\n",
    "import tiktoken\n",
    "\n",
    "# ノードパーサーの準備\n",
    "text_splitter = SentenceSplitter(\n",
    "    paragraph_separator=paragraph_separator,\n",
    "    secondary_chunking_regex = secondary_chunking_regex,\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap,\n",
    ")\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    text_splitter=text_splitter\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    node_parser=node_parser\n",
    ")\n",
    "service_context.node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46cc018f-ace7-4e41-8e68-7384dd2bcc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "946\n",
      "600\n",
      "IA0248_02tanaka (2021-03-05 15:41)一般論文雑談対話応答における連続する事態の一貫性と対話継続性の関係田中　翔平 †・吉野幸一郎 †,††・須藤　克仁 †・中村　　哲 †雑談対話システムの評価指標として，ユーザとの対話を継続させる働きを表す，対話継続性が挙げられる．対話モデルの先行研究において，対話継続性の向上には，システム発話の一貫性が重要であると考えられている．そこで本論文では，対話モデルより生成された応答候補を，対話中に含まれる事態の一貫性に基づいてリランキングする手法を提案する．提案手法は対話に含まれる事態の一貫性（「ストレスが溜まる」と「発散する」は関連した事態である，など）を考慮することで，選択される応答の一貫性，対話継続性の向上を図る．本研究では異なる 2 つの手法を考案した．一つ目の手法は統計的に獲得された因果関係ペアとのマッチングにより，対話中の事態の一貫性を考慮し，二つ目の手法は Coherence Model によって，対話の一貫性を考慮する．自動評価の結果，これらの手法では応答中の単語選択の観点では一貫性は向上していることが確認された．一方で，人手評価の結果では，応答の主観的な一貫性は明確に向上しないものの，一つ目の方法により対話継続性が向上するという，一見して矛盾する結果が確認された．\n"
     ]
    }
   ],
   "source": [
    "node_list = service_context.node_parser.get_nodes_from_documents(documents)\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "print(len(node_list))\n",
    "for node in node_list:\n",
    "    print(len(enc.encode(node.text)))\n",
    "    print(len(node.text))\n",
    "    print(node.text.replace(\"\\n\",\"\"))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c854de5-7f4f-4638-b1ed-1f19f3bf1f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents=documents,vector_store=vector_store,service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9863d-bff8-48f4-bd19-6f1d414c4595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
